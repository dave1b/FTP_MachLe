{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ost_logo.png\" width=\"240\" height=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Machine Learning </b> <br> MSE FTP MachLe <br> \n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> Christoph Würsch </a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab13: A3 Q-Learning in the Grid-World\n",
    "(`Lab13_A3_QLearning_GridBoard_TEMPLATE.ipynb`)\n",
    "\n",
    "[Adapted from Jeremy Zhang:](https://towardsdatascience.com/implement-grid-world-with-q-learning-51151747b455)\n",
    "\n",
    "Whereas $V(s)$ is a mapping from state $s$ to estimated value of that state, the $Q$ function — $Q(s, a)$ is only one component different from $V$ function. Instead of thinking that you receive a value when you are in a specific state $s$, think one step forward, you are in a state $s$ and by taking a specific action $a$ you receive a corresponding value. \n",
    "\n",
    "The result of grid world using value iteration was that we get a estimated value $V(s)$ for each state, but to have our policy $\\pi(s, a)$, which is a mapping from state $s$ to action $a$, we need to go one step further by choosing the action that could get into the maximum value of next state. However, in Q-function, state and action are paired in the first place, which means when one has the optimal Q-function, he has the optimal action of that state.\n",
    "\n",
    "Besides the Q-function, we are going to add more fun to our game:\n",
    "- The agent action is **non-deterministic**, i.e. there is a transition probability $P_{ss'}$ from one state $s$ to another state $s'$\n",
    "- Reward decays with ratio $\\gamma$\n",
    "\n",
    "Non-deterministic means that the agent will not be able to go where it intends to go. When it takes an action, it will has a probability to crash in a different action.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"board2.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "---\n",
    "When the agent moving up, it has **0.8** probability moving up and **0.1** probability of going left or right. (non-deterministic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning algorithm\n",
    "\n",
    "\n",
    "One of the early breakthroughs in reinforcement learning was the development of an\n",
    "off-policy TD control algorithm known as Q-learning (Watkins, 1989), defined by\n",
    "\n",
    "$$ Q(s_t,a_t) \\leftarrow Q(s_t,a_t)+ \\alpha \\cdot \\left[ R_{t+1}+ \\gamma \\max_a Q(s_{t+1},a)-Q(s_t,a_t)\\right]$$\n",
    "\n",
    "- In this case, the learned action-value function, $Q$, directly approximates $Q^*$, the optimal action-value function, *independent of the policy being followed*. This dramatically simplifies the analysis of the algorithm and enabled early convergence proofs. The policy still has an effect in that it determines which state–action pairs are visited and updated. The policy can directly be derived from $Q$, e.g. using an $\\varepsilon$-greedy approach.\n",
    "- However, all that is required for correct convergence is that all pairs continue to be updated. Under this assumption and a variant of the usual stochastic approximation conditions on the sequence of step-size parameters, $Q$ has been shown to converge with probability $1$ to $Q^*$. The Q-learning algorithm is shown below in procedural form.\n",
    "\n",
    "\n",
    "\n",
    "The *Q-learning-algorithm* is intrinsically **off-policy**, since it does not draw samples from a given policy $\\pi$.\n",
    "\n",
    "1. **Perform an action** $a$ in a state $s$ to end up in $s'$ with reward $r$, i.e. consider the tuple $(s,a,s',r)$\n",
    "2. **Compute the intermediate Q-value:**\n",
    "$$ \\hat{Q}(s,a)=R(s,a,s')+\\gamma \\max_{a'} Q_k(s',a')$$\n",
    "\n",
    "3. Incorporate that new evidence into the existing value using a **running average**: ($\\alpha$ is the learning rate)\n",
    "$$Q_{k+1}(s,a)=(1-\\alpha)\\cdot Q_k(s,a)+\\alpha\\cdot \\hat{Q}(s,a)$$\n",
    "\n",
    "This can be rewritten in a **gradient-descent update rule** fashion as:\n",
    "\n",
    "$$ Q_{k+1}(s,a) = Q_k(s,a)+\\alpha \\cdot \\left( \\hat{Q}(s,a)-Q_k(s,a) \\right)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 4\n",
    "WIN_STATE = (0, 3)\n",
    "LOSE_STATE = (1, 3)\n",
    "START = (2, 0)\n",
    "DETERMINISTIC = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, state=START):\n",
    "        self.board = np.zeros([BOARD_ROWS, BOARD_COLS])\n",
    "        self.board[1, 1] = -1\n",
    "        self.state = state\n",
    "        self.isEnd = False\n",
    "        self.determine = DETERMINISTIC\n",
    "        \n",
    "    def giveReward(self):\n",
    "        if self.state == WIN_STATE:\n",
    "            return 1\n",
    "        elif self.state == LOSE_STATE:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def isEndFunc(self):\n",
    "        if (self.state == WIN_STATE) or (self.state == LOSE_STATE):\n",
    "            self.isEnd = True\n",
    "\n",
    "    def _chooseActionProb(self, action):\n",
    "        if action == \"up\":\n",
    "            return np.random.choice([\"up\", \"left\", \"right\"], p=[0.8, 0.1, 0.1])\n",
    "        if action == \"down\":\n",
    "            return np.random.choice([\"down\", \"left\", \"right\"], p=[0.8, 0.1, 0.1])\n",
    "        if action == \"left\":\n",
    "            return np.random.choice([\"left\", \"up\", \"down\"], p=[0.8, 0.1, 0.1])\n",
    "        if action == \"right\":\n",
    "            return np.random.choice([\"right\", \"up\", \"down\"], p=[0.8, 0.1, 0.1])\n",
    "        \n",
    "    def nxtPosition(self, action):\n",
    "        \"\"\"\n",
    "        action: up, down, left, right\n",
    "        -------------\n",
    "        0 | 1 | 2| 3|\n",
    "        1 |\n",
    "        2 |\n",
    "        return next position on board\n",
    "        \"\"\"\n",
    "        if self.determine:\n",
    "            if action == \"up\":\n",
    "                nxtState = (self.state[0]-1, self.state[1])\n",
    "            elif action == \"down\":\n",
    "                nxtState = (self.state[0]+1, self.state[1])\n",
    "            elif action == \"left\":\n",
    "                nxtState = (self.state[0], self.state[1]-1)\n",
    "            else:\n",
    "                nxtState = (self.state[0], self.state[1]+1)\n",
    "            self.determine = False\n",
    "        else:\n",
    "            # non-deterministic\n",
    "            action = self._chooseActionProb(action)\n",
    "            self.determine = True\n",
    "            nxtState = self.nxtPosition(action)\n",
    "                        \n",
    "        # if next state is legal\n",
    "        if (nxtState[0] >= 0) and (nxtState[0] <= 2):\n",
    "            if (nxtState[1] >= 0) and (nxtState[1] <= 3):\n",
    "                if nxtState != (1, 1):\n",
    "                    return nxtState\n",
    "        return self.state\n",
    "    \n",
    "    def showBoard(self):\n",
    "        self.board[self.state] = 1\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('-----------------')\n",
    "            out = '| '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = '*'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'z'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = '0'\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-----------------')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Difference Learning\n",
    "\n",
    "- Firstly, at each step, an agent takes action $a$ , collecting corresponding reward $r$ , and moves from state $s$ to $s'$. So a whole pair of $(s, a, s',r)$ is considered at each step.\n",
    "- Secondly, we give an estimation of current $Q$ value, which equals to current reward plus maximum $Q$ value of next state times a decay rate $\\gamma$. One thing worth noting is that we set all intermediate reward as 0, so the agent won’t be able to collect any non-zero reward until the end state, either 1 or -1.(This is not compulsory, you can try out other reward and see how the agent acts)\n",
    "- Lastly, we update the estimation of the current Q value by adding $\\alpha$ times a **temporal difference** (which is the difference between new estimation and current value).\n",
    "\n",
    "### Action\n",
    "- In terms of action taking, it will still be based on exploration rate.\n",
    "- When the agent exploits the state, **it will take the action that maximises the Q value according to current estimation of Q-value**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.states = []  # record position and action taken at the position\n",
    "        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n",
    "        self.State = Environment()\n",
    "        self.isEnd = self.State.isEnd\n",
    "        self.lr = 0.2\n",
    "        self.exp_rate = 0.3\n",
    "        self.decay_gamma = 0.9\n",
    "\n",
    "        # initial Q values\n",
    "        self.Q_values = {}\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                self.Q_values[(i, j)] = {}\n",
    "                for a in self.actions:\n",
    "                    self.Q_values[(i, j)][a] = 0  # Q value is a dict of dict  \n",
    "    \n",
    "    def chooseAction(self):\n",
    "        # choose action with most expected value\n",
    "        mx_nxt_reward = 0\n",
    "        action = \"\"\n",
    "        \n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            action = np.random.choice(self.actions)\n",
    "        else:\n",
    "            # greedy action\n",
    "            for a in self.actions:\n",
    "                current_position = self.State.state\n",
    "                nxt_reward = self.Q_values[current_position][a]\n",
    "                if nxt_reward >= mx_nxt_reward:\n",
    "                    action = a\n",
    "                    mx_nxt_reward = nxt_reward\n",
    "            #print(\"current pos: {}, greedy aciton: {}\".format(self.State.state, action))\n",
    "        return action\n",
    "    \n",
    "    def takeAction(self, action):\n",
    "        position = self.State.nxtPosition(action)\n",
    "        # update State\n",
    "        return Environment(state=position)     \n",
    "    \n",
    "    def reset(self):\n",
    "        self.states = []\n",
    "        self.State = Environment()\n",
    "        self.isEnd = self.State.isEnd\n",
    "    \n",
    "    def play(self, rounds=10):\n",
    "        i = 0\n",
    "        while i < rounds:\n",
    "            # to the end of game back propagate reward\n",
    "            if self.State.isEnd:\n",
    "                # back propagate\n",
    "                reward = self.State.giveReward()\n",
    "                for a in self.actions:\n",
    "                    self.Q_values[self.State.state][a] = reward\n",
    "                print(\"Game End Reward\", reward)\n",
    "                for s in reversed(self.states):\n",
    "                    current_q_value = self.Q_values[s[0]][s[1]]\n",
    "                    reward = current_q_value + self.lr*(self.decay_gamma*reward - current_q_value)\n",
    "                    self.Q_values[s[0]][s[1]] = round(reward, 3)\n",
    "                self.reset()\n",
    "                i += 1\n",
    "            else:\n",
    "                action = self.chooseAction()\n",
    "                # append trace\n",
    "                self.states.append([(self.State.state), action])\n",
    "                print(\"current position {} action {}\".format(self.State.state, action))\n",
    "                # by taking the action, it reaches the next state\n",
    "                self.State = self.takeAction(action)\n",
    "                # mark is end\n",
    "                self.State.isEndFunc()\n",
    "                print(\"nxt state\", self.State.state)\n",
    "                print(\"---------------------\")\n",
    "                self.isEnd = self.State.isEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       " (0, 1): {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       " (0, 2): {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       " (0, 3): {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       " (1, 0): {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       " (1, 1): {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       " (1, 2): {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       " (1, 3): {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       " (2, 0): {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       " (2, 1): {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       " (2, 2): {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       " (2, 3): {'up': 0, 'down': 0, 'left': 0, 'right': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag.Q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current position (2, 0) action down\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action right\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action up\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action left\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action down\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action up\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action up\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action up\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action up\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action left\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action right\n",
      "nxt state (2, 3)\n",
      "---------------------\n",
      "current position (2, 3) action left\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action up\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action down\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action up\n",
      "nxt state (1, 3)\n",
      "---------------------\n",
      "Game End Reward -1\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action up\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action up\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action right\n",
      "nxt state (1, 3)\n",
      "---------------------\n",
      "Game End Reward -1\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action right\n",
      "nxt state (2, 3)\n",
      "---------------------\n",
      "current position (2, 3) action left\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action up\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action right\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action left\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action down\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action right\n",
      "nxt state (2, 3)\n",
      "---------------------\n",
      "current position (2, 3) action left\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action right\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action left\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action down\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action up\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action down\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action right\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action right\n",
      "nxt state (2, 3)\n",
      "---------------------\n",
      "current position (2, 3) action right\n",
      "nxt state (2, 3)\n",
      "---------------------\n",
      "current position (2, 3) action right\n",
      "nxt state (2, 3)\n",
      "---------------------\n",
      "current position (2, 3) action right\n",
      "nxt state (2, 3)\n",
      "---------------------\n",
      "current position (2, 3) action left\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action right\n",
      "nxt state (2, 3)\n",
      "---------------------\n",
      "current position (2, 3) action right\n",
      "nxt state (2, 3)\n",
      "---------------------\n",
      "current position (2, 3) action right\n",
      "nxt state (1, 3)\n",
      "---------------------\n",
      "Game End Reward -1\n",
      "current position (2, 0) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action down\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action right\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action right\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action right\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action right\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action down\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action down\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action right\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action left\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action up\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action up\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action right\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action up\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action left\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action left\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action down\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action left\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action down\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action down\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action down\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action down\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action up\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action down\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action down\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action right\n",
      "nxt state (1, 3)\n",
      "---------------------\n",
      "Game End Reward -1\n",
      "current position (2, 0) action left\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action left\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action down\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action up\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action left\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action up\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action left\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action left\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action down\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action down\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action left\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action down\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action down\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action up\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action left\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action right\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action left\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action up\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action left\n",
      "nxt state (2, 2)\n",
      "---------------------\n",
      "current position (2, 2) action left\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action left\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action down\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action up\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action left\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action up\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action up\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action up\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action down\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action down\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action right\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action left\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action left\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action down\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action down\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action left\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action down\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action down\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action down\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action down\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action up\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action left\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action up\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action left\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action up\n",
      "nxt state (1, 3)\n",
      "---------------------\n",
      "Game End Reward -1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action down\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action left\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action right\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action down\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action up\n",
      "nxt state (1, 3)\n",
      "---------------------\n",
      "Game End Reward -1\n",
      "current position (2, 0) action left\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action left\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action down\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action right\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action down\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action right\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action up\n",
      "nxt state (2, 1)\n",
      "---------------------\n",
      "current position (2, 1) action up\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (1, 2)\n",
      "---------------------\n",
      "current position (1, 2) action left\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action left\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action down\n",
      "nxt state (2, 0)\n",
      "---------------------\n",
      "current position (2, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (1, 0)\n",
      "---------------------\n",
      "current position (1, 0) action up\n",
      "nxt state (0, 0)\n",
      "---------------------\n",
      "current position (0, 0) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 1)\n",
      "---------------------\n",
      "current position (0, 1) action right\n",
      "nxt state (0, 2)\n",
      "---------------------\n",
      "current position (0, 2) action right\n",
      "nxt state (0, 3)\n",
      "---------------------\n",
      "Game End Reward 1\n"
     ]
    }
   ],
   "source": [
    "ag.play(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): {'up': 0.277, 'down': 0.072, 'left': 0.207, 'right': 0.401},\n",
       " (0, 1): {'up': 0.298, 'down': 0.312, 'left': 0.182, 'right': 0.545},\n",
       " (0, 2): {'up': 0.355, 'down': 0.253, 'left': 0.034, 'right': 0.718},\n",
       " (0, 3): {'up': 1, 'down': 1, 'left': 1, 'right': 1},\n",
       " (1, 0): {'up': 0.248, 'down': 0.126, 'left': 0.058, 'right': 0.148},\n",
       " (1, 1): {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       " (1, 2): {'up': -0.126, 'down': 0.001, 'left': 0.156, 'right': -0.087},\n",
       " (1, 3): {'up': -1, 'down': -1, 'left': -1, 'right': -1},\n",
       " (2, 0): {'up': 0.244, 'down': 0.01, 'left': 0.046, 'right': 0.057},\n",
       " (2, 1): {'up': 0.075, 'down': -0.001, 'left': 0.092, 'right': -0.006},\n",
       " (2, 2): {'up': -0.008, 'down': 0, 'left': 0.009, 'right': -0.045},\n",
       " (2, 3): {'up': 0, 'down': 0, 'left': -0.005, 'right': -0.136}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag.Q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
