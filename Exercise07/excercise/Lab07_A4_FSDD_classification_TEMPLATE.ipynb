{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ost_logo.png\" width=\"240\" height=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Machine Learning </b> <br> MSE FTP MachLe <br> \n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> Christoph Würsch </a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab07: A4 Free Spoken Digits Classification (FSDD dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we introduce a possible approach to the *Free Spoken Digit Dataset* classification problem.  \n",
    "The machine learning models are able to predict audio labels with an accuracy of 98%. \n",
    "\n",
    "This notebook was inspired by: [Inam ur Rehman](https://www.kaggle.com/iinaam), Data Analyst at PIC - Servizi per l'informatica, Turin, Piedmont, Italy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In particular\n",
    "we shall see:\n",
    "1. How to play audio files in Python\n",
    "2. How to sample audio signal into digital form\n",
    "3. How to remove leading and trailing noise (e.g. silence) from audio\n",
    "4. How to set a naive baseline (use of time domain)\n",
    "5. How to combine time and frequency domain features (Spectogram)\n",
    "6. How to train, build and predict using different machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "ExecuteTime": {
     "end_time": "2024-04-04T15:45:00.221256Z",
     "start_time": "2024-04-04T15:45:00.117232Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m wavfile\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mipd\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrosa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m melspectrogram\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrosa\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m power_to_db\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrosa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meffects\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m trim\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import IPython.display as ipd\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa import power_to_db\n",
    "from librosa.effects import trim\n",
    "\n",
    "# plotting utilities\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "plt.rcParams[\"figure.titleweight\"] = 'bold' \n",
    "plt.rcParams[\"figure.titlesize\"] = 'large'\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "#plt.style.use('fivethirtyeight')\n",
    "\n",
    "rs = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "- The Free Spoken Digit Dataset is a collection of audio recordings of utterances of digits (“zero” to “nine”) from different people.  \n",
    "- You can download the dataset [here](https://www.kaggle.com/datasets/joserzapata/free-spoken-digit-dataset-fsdd): https://www.kaggle.com/datasets/joserzapata/free-spoken-digit-dataset-fsdd\n",
    "- Download the data an your local drive and set the directory path accordingly.\n",
    "\n",
    "The goal of this competition is to correctly identify the digit being uttered in each recording.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T15:45:00.222879Z",
     "start_time": "2024-04-04T15:45:00.222837Z"
    }
   },
   "outputs": [],
   "source": [
    "files = 'E:/temp/ML_datasets/recordings'\n",
    "ds_files = listdir(files)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for file in ds_files:\n",
    "    label = int(file.split(\"_\")[0])\n",
    "    rate, data = wavfile.read(join(files, file))\n",
    "    X.append(data.astype(np.float16))\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic EDA\n",
    "\n",
    "### (a) Analyze whether the dataset is well balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is well balanced: for each of the classes we have 300 samples in dataset.  \n",
    "All recordings are sampled at the rate of 8 kHZ\n",
    "\n",
    "Audio signals have different length.  \n",
    "Some of them have leading and silence intervals. Let's analyze that first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Plot a histogram of the length of the spoken words.\n",
    "\n",
    "- What is the average length of the spoken words?\n",
    "- what is the standard deviation of the length of the words?\n",
    "- What is the 90% percentile of the length of the records?\n",
    "- What is the number of outliers that excede the 90% quantile?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 8000\n",
    "def show_length_distribution(signals, rate = 8000):\n",
    "    sampel_times = [len(x)/rate for x in signals]\n",
    "\n",
    "\n",
    "    f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.20, .80)})\n",
    "\n",
    "    # Add a graph in each part\n",
    "    sns.boxplot(x = sampel_times, ax=ax_box, linewidth = 0.9, color=  '#9af772')\n",
    "    sns.histplot(x = sampel_times, ax=ax_hist, bins = 'fd', kde = True)\n",
    "\n",
    "    # Remove x axis name for the boxplot\n",
    "    ax_box.set(xlabel='')\n",
    "\n",
    "\n",
    "    title = 'Audio signal lengths'\n",
    "    x_label = 'duration (seconds)'\n",
    "    y_label = 'count'\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    ax_hist.set_xlabel(x_label)\n",
    "    ax_hist.set_ylabel(y_label)\n",
    "    plt.show()\n",
    "    return sampel_times\n",
    "\n",
    "\n",
    "lengths = show_length_distribution(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 90\n",
    "np.percentile(lengths, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_outliers = sum(map(lambda x: x > np.percentile(lengths, q), lengths))\n",
    "print(f'Values outside {q} percentile: {tot_outliers}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These outliers will be later handled according to the proposed solutions.  \n",
    "\n",
    "### (c) Play and display one of the records.\n",
    "\n",
    "Have a look at some extreme cases. Use `IPython.display.ipd` to display and play the audio signal.\n",
    "- Look at the longest signal\n",
    "- look at the shortest signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Longest_audio = np.argmax([len(x) for x in X])\n",
    "plt.plot(X[Longest_audio])\n",
    "plt.title(\"Longest audio signal\");\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('amplitude (arb.)')\n",
    "ipd.Audio(X[Longest_audio], rate=rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shortest_audio = np.argmin([len(x) for x in X])\n",
    "plt.plot(X[Shortest_audio])\n",
    "plt.title(\"Shortest audio signal\");\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('amplitude (arb.)')\n",
    "ipd.Audio(X[Shortest_audio], rate=rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time domain analysis\n",
    "###  (d) Feature Extraction from time domain\n",
    "\n",
    "- Remove the leading and trailing silence from signals to see if we get different distribution of length. \n",
    "- Use `from librosa.effects import trim` to trim the signals. By default anything below 10 db is considered as silence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default anything below 10 db is considered as silence\n",
    "def remove_silence(sample, sr= 8000, top_db = 10):\n",
    "    ....\n",
    "    return yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = [remove_silence(x) for x in X]\n",
    "\n",
    "show_length_distribution(X_tr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore different recordings to see how they are trimmed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_tr[Longest_audio])\n",
    "plt.title(\"Longest recording after trimming\");\n",
    "\n",
    "plt.grid(True); plt.xlabel('sample'); plt.ylabel('amplitude (arb.)')\n",
    "ipd.Audio(X_tr[Longest_audio], rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Create a matrix with uniform length of columns to allign all recordings.  \n",
    "\n",
    "- All signals should have `rate*0.8=6400` data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(rate * 0.8) # 0.8 is the upper limit of trimmed audio length\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_uniform = []\n",
    "for x in X_tr:\n",
    "    ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Audio feature generation\n",
    "\n",
    "- Write a function that creates bins of same width and computes mean and standard deviation on those bins as features for audio classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_bins(X, bins = 20):\n",
    "    \"\"\"This functions creates bins of same width and computes mean and standard deviation on those bins\n",
    "    \"\"\"\n",
    "    X_mean_sd = []\n",
    "    for x in X:\n",
    "        x_mean_sd = []\n",
    "        As = np.array_split(np.array(x), 20)\n",
    "        for a in As:\n",
    "            mean = np.round(a.mean(dtype=np.float64), 4)\n",
    "            sd = np.round(a.std(dtype=np.float64), 4)\n",
    "            x_mean_sd.extend([mean, sd])\n",
    "\n",
    "        X_mean_sd.append(x_mean_sd)\n",
    "    return np.array(X_mean_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) Random Forest classifier on the time domain features\n",
    "\n",
    "- Train a random forest clasifier on the dataset consisting of the mean and the standard deviation of the bins.\n",
    "- Hypertune the random forest classifier using a grid search over the following parameters:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100,150,200],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"min_impurity_decrease\": [0.0,0.05,0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of bins is an hyperparameter.  \n",
    "We will try different n. of bins with default configurations of Random Forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Hyperperameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_time = into_bins(X_uniform, 60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_time, y, test_size = 0.20, random_state = rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100,150,200],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"min_impurity_decrease\": [0.0,0.05,0.1]\n",
    "}\n",
    "\n",
    "clf = RFC(random_state = rs, n_jobs = -1 )\n",
    "grid_search = GridSearchCV(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a spectoral representation of audio signals, we get time on x-axis and different frequencies on y-axis.\n",
    "Values in the matrix represent different properties of audio singal related to particular time and frequency. (amplitude, power ecc)\n",
    "\n",
    "### (h) Plot a power spectrogram of an arbitrary sound sample spectrogram on log scale (dB)\n",
    "\n",
    "- Plot a power spectrogram of an arbitrary sound sample spectrogram on log scale (dB)\n",
    "- use `powerSpectrum, freqenciesFound, time, imageAxis = plt.specgram(X[...], Fs=rate, scale = \"dB\")`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the spectrogram of power on log scale\n",
    "\n",
    "# fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "powerSpectrum, freqenciesFound, time, imageAxis = plt.specgram(X[np.random.randint(100)], Fs=rate, scale = \"dB\")\n",
    "cbar = plt.gcf().colorbar(imageAxis)\n",
    "cbar.set_label('db')\n",
    "plt.grid()\n",
    "plt.suptitle(\"Spectrogram of a signal\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) Feature extraction from MEL spectogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that both time and frequency domains contain useful information regarding the recordings.  \n",
    "We can leverage both by using the spectrogram of each signal.\n",
    "  \n",
    "To extract features from a MEL spectrogram of given signal, we divide it into `N x N` sub matrices of nearly identical shape.  \n",
    "- Compute the *mean* and *standard deviation* of these submatrices and consider them as features set.  \n",
    "- The number `N` of sub matrices is considered as an *hyperparameter* for the classifier.\n",
    "- You can use the helper function `ft_mean_std(X, n, f_s = 8000)` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_mean_std(X, n, f_s = 8000):\n",
    "    \"\"\"Computes mean and std of each n x n block of spectrograms of X\n",
    "       empty bins contains mean values of that column matrices\n",
    "       \n",
    "    Parameters:\n",
    "        X: 2-d sampling array\n",
    "        n: number of rows or columns to split spectogram\n",
    "    Returns:\n",
    "        A 2-d numpy array - feature Matrix with n x 2 x n features as columns\n",
    "    \"\"\"\n",
    "    X_sp = [] #feature matrix\n",
    "    for x in X:\n",
    "        sp = power_to_db(melspectrogram(y=x, n_fft= len(x)))\n",
    "        x_sp = [] #current feature set\n",
    "        # split the rows\n",
    "        for v_split in np.array_split(sp, n, axis = 0):\n",
    "            # split the columns\n",
    "            for h_split in np.array_split(v_split, n, axis = 1):\n",
    "                if h_split.size == 0: #happens when number of culumns < n\n",
    "                    m = np.median(v_split).__round__(4)\n",
    "                    sd = np.std(v_split).__round__(4)\n",
    "                else:\n",
    "                    m = np.mean(h_split).__round__(4)\n",
    "                    sd = np.std(h_split).__round__(4)\n",
    "                x_sp.extend([m,sd])\n",
    "                \n",
    "        X_sp.append(x_sp)\n",
    "\n",
    "    return np.array(X_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ft = ft_mean_std(X, 10)\n",
    "len(X_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (j) Determine the optimum number `N` of bins\n",
    "- Determine the optimum number `N` of bins in time-frequency domain (`N` along the time dimension and `N` along the frequency dimension).\n",
    "- Program a for loop that varies `N` in the `range(3,20,2)` and train a Random Forest Classifier on the training set (80%) and validate it on the validation set (20%).\n",
    "- Select the optimum number of bins `N`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores = [x[0][1] for x in scores.values()]\n",
    "x = scores.keys()\n",
    "\n",
    "plt.plot(x, rf_scores, 'o-', label = 'RF')\n",
    "plt.grid(True)\n",
    "plt.legend(loc = (1,.8))\n",
    "plt.suptitle(\"Model evaluation on different n. of bins\")\n",
    "plt.xlabel(\"n. of bins\")\n",
    "plt.ylabel('mean f-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select 10 as initial number of bins. Both models are stable in the neighborhood of 10.  \n",
    "we can check the performance of models with their optimal configurations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ft = ft_mean_std(X, 10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ft, y, test_size = 0.20, random_state = rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (k) Hypertune a Random Forest Classifier \n",
    "- Hypertune a Random Forest Classifier using `N=10` bins using a 5-fold crossvalidation with the following grid search:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100,150,200],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"min_impurity_decrease\": [0.0,0.05,0.1]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
