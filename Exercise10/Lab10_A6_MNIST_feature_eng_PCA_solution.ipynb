{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ost_logo.png\" width=\"240\" height=\"240\" align=\"right\"/>\n",
    "<div style=\"text-align: left\"> <b> Machine Learning </b> <br> MSE FTP MachLe <br> \n",
    "<a href=\"mailto:christoph.wuersch@ost.ch\"> Christoph Würsch </a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lab 11, A6: Feature Engineering using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:25:23.231767Z",
     "start_time": "2024-05-06T14:25:22.984940Z"
    }
   },
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"dim_reduction\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Loading the MINST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Load the MNIST dataset (introduced in chapter 3) and split it into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing).*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:25:23.613691Z",
     "start_time": "2024-05-06T14:25:23.236361Z"
    }
   },
   "source": [
    "from sklearn.decomposition import PCA"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:25:25.573714Z",
     "start_time": "2024-05-06T14:25:23.614408Z"
    }
   },
   "source": [
    "#from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:25:25.581048Z",
     "start_time": "2024-05-06T14:25:25.574419Z"
    }
   },
   "source": [
    "X_train = mnist['data'][:60000].values\n",
    "y_train = mnist['target'][:60000].astype(int).values\n",
    "\n",
    "X_test = mnist['data'][60000:].values\n",
    "y_test = mnist['target'][60000:].astype(int).values"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:25:25.584939Z",
     "start_time": "2024-05-06T14:25:25.582614Z"
    }
   },
   "source": [
    "X_train\n",
    "y_train"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:25:25.705508Z",
     "start_time": "2024-05-06T14:25:25.585405Z"
    }
   },
   "source": [
    "#we save the data to disk so that we can fetch it fast if we need it using the next cell:\n",
    "\n",
    "import pandas as pd\n",
    "#mnist.data.to_pickle('mnist_data_784.pkl')\n",
    "#mnist.target.to_pickle('mnist_label_784.pkl');\n",
    "\n",
    "#read data from pickle file if there is no internet connection\n",
    "X=pd.read_pickle('mnist_data_784.pkl').values\n",
    "y=pd.read_pickle('mnist_label_784.pkl').values\n",
    "\n",
    "X_train = X[:60000:,:]\n",
    "y_train = y[:60000].astype(int)\n",
    "\n",
    "X_test = X[60000:,:]\n",
    "y_test = y[60000:].astype(int)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Training a Random Forest classifier on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Train a Random Forest classifier on the dataset and time how long it takes, then evaluate the resulting model on the test set.*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:25:25.891109Z",
     "start_time": "2024-05-06T14:25:25.706155Z"
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(random_state=42)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:25:47.513133Z",
     "start_time": "2024-05-06T14:25:25.891964Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "t1 = time.time()"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:25:47.515401Z",
     "start_time": "2024-05-06T14:25:47.513893Z"
    }
   },
   "source": [
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 21.62s\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:25:47.651213Z",
     "start_time": "2024-05-06T14:25:47.515971Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9691"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Use PCA to reduce the dataset’s dimensionality, with an explained variance ratio of 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Next, use PCA to reduce the dataset's dimensionality, with an explained variance ratio of 95%.*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:25:50.992558Z",
     "start_time": "2024-05-06T14:25:47.652013Z"
    }
   },
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_reduced = pca.fit_transform(X_train)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Train a new Random Forest classifier on the reduced dataset and see how long it takes. Was training much faster?*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:26:53.573764Z",
     "start_time": "2024-05-06T14:25:50.994836Z"
    }
   },
   "source": [
    "rnd_clf2 = RandomForestClassifier(random_state=42)\n",
    "t0 = time.time()\n",
    "rnd_clf2.fit(X_train_reduced, y_train)\n",
    "t1 = time.time()"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:26:53.576062Z",
     "start_time": "2024-05-06T14:26:53.574444Z"
    }
   },
   "source": [
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 62.58s\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no! Training is actually more than twice slower now! How can that be? Well, as we saw in this chapter, dimensionality reduction does not always lead to faster training time: it depends on the dataset, the model and the training algorithm. See figure 8-6 (the `manifold_decision_boundary_plot*` plots above). If you try a softmax classifier instead of a random forest classifier, you will find that training time is reduced by a factor of 3 when using PCA. Actually, we will do this in a second, but first let's check the precision of the new random forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Evaluate the classifier on the test set: how does it compare to the previous classifier?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:26:53.822747Z",
     "start_time": "2024-05-06T14:26:53.578157Z"
    }
   },
   "source": [
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "y_pred = rnd_clf2.predict(X_test_reduced)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9474"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common for performance to drop slightly when reducing dimensionality, because we do lose some useful signal in the process. However, the performance drop is rather severe in this case. So PCA really did not help: it slowed down training and reduced performance. :(\n",
    "\n",
    "Let's see if it helps when using softmax regression:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:28:07.452610Z",
     "start_time": "2024-05-06T14:26:53.824389Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42,max_iter=1000)\n",
    "t0 = time.time()\n",
    "log_clf.fit(X_train, y_train)\n",
    "t1 = time.time()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davebrunner/.local/share/virtualenvs/FTP_MachLe-TAxQAUJy/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:28:07.470481Z",
     "start_time": "2024-05-06T14:28:07.455291Z"
    }
   },
   "source": [
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 73.63s\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:28:07.508689Z",
     "start_time": "2024-05-06T14:28:07.472074Z"
    }
   },
   "source": [
    "y_pred = log_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9216"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so softmax regression takes much longer to train on this dataset than the random forest classifier, plus it performs worse on the test set. But that's not what we are interested in right now, we want to see how much PCA can help softmax regression. Let's train the softmax regression model using the reduced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:28:38.636348Z",
     "start_time": "2024-05-06T14:28:07.510492Z"
    }
   },
   "source": [
    "log_clf2 = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42,max_iter=1000)\n",
    "t0 = time.time()\n",
    "log_clf2.fit(X_train_reduced, y_train)\n",
    "t1 = time.time()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davebrunner/.local/share/virtualenvs/FTP_MachLe-TAxQAUJy/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:28:38.656744Z",
     "start_time": "2024-05-06T14:28:38.650731Z"
    }
   },
   "source": [
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 31.12s\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Reducing dimensionality led to a 4× speedup. :)  Let's the model's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:28:38.671679Z",
     "start_time": "2024-05-06T14:28:38.658612Z"
    }
   },
   "source": [
    "y_pred = log_clf2.predict(X_test_reduced)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9234"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very slight drop in performance, which might be a reasonable price to pay for a 4× speedup, depending on the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__So there you have it: PCA can give you a formidable speedup... but not always!__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "nav_menu": {
   "height": "352px",
   "width": "458px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
